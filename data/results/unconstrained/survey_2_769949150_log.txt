Starting compilation
Compilation took 9.14917516708374 seconds.

Fixed weights: {1: pos_neg_weight(p_weight=s(0.09,0), n_weight=s(0.91,0)), 2: pos_neg_weight(p_weight=s(0.3,0), n_weight=s(0.7,0)), 3: pos_neg_weight(p_weight=s(t,0), n_weight=s(t,0)), 4: pos_neg_weight(p_weight=s(0.6,0), n_weight=s(0.4,0)), 5: True, 11: True, 17: pos_neg_weight(p_weight=s(0.25,0), n_weight=s(0.75,0)), 20: pos_neg_weight(p_weight=s(0.4,0), n_weight=s(0.6,0)), 21: True, 27: True, 33: pos_neg_weight(p_weight=s(0.36,0), n_weight=s(0.64,0)), 36: pos_neg_weight(p_weight=s(0.28,0), n_weight=s(0.72,0)), 37: pos_neg_weight(p_weight=s(0.5,0), n_weight=s(0.5,0)), 38: True, 39: True, 47: pos_neg_weight(p_weight=s(0.3,0), n_weight=s(0.7,0)), 48: True, 56: pos_neg_weight(p_weight=s(0.12,0), n_weight=s(0.88,0)), 57: pos_neg_weight(p_weight=s(0.2,0), n_weight=s(0.8,0)), 58: True, 66: True, 72: pos_neg_weight(p_weight=s(0.1,0), n_weight=s(0.9,0)), 75: pos_neg_weight(p_weight=s(t,0), n_weight=s(t,0)), 76: pos_neg_weight(p_weight=s(0.3,0), n_weight=s(0.7,0)), 79: True, 85: pos_neg_weight(p_weight=s(0.8,0), n_weight=s(0.2,0)), 88: pos_neg_weight(p_weight=s(0.75,0), n_weight=s(0.25,0)), 89: pos_neg_weight(p_weight=s(0.75,0), n_weight=s(0.25,0)), 90: True, 93: pos_neg_weight(p_weight=s(0.64,0), n_weight=s(0.36,0)), 94: True, 97: pos_neg_weight(p_weight=s(0.72,0), n_weight=s(0.28,0)), 98: True, 101: pos_neg_weight(p_weight=s(0.7,0), n_weight=s(0.3,0)), 102: True, 105: pos_neg_weight(p_weight=s(0.88,0), n_weight=s(0.12,0)), 106: True, 109: pos_neg_weight(p_weight=s(0.9,0), n_weight=s(0.1,0)), 110: True, 113: True, 121: True, 127: pos_neg_weight(p_weight=s(0.08,0), n_weight=s(0.92,0)), 130: pos_neg_weight(p_weight=s(0.04,0), n_weight=s(0.96,0)), 133: True, 139: True, 147: pos_neg_weight(p_weight=s(0.92,0), n_weight=s(0.08,0)), 148: True, 151: pos_neg_weight(p_weight=s(0.96,0), n_weight=s(0.04,0)), 152: pos_neg_weight(p_weight=s(t,0), n_weight=s(t,0)), 155: pos_neg_weight(p_weight=s(0.96,0), n_weight=s(0.04,0)), 156: True, 159: True, 165: pos_neg_weight(p_weight=s(0.25,0), n_weight=s(0.75,0)), 166: True, 169: pos_neg_weight(p_weight=s(0.2,0), n_weight=s(0.8,0)), 170: True, 173: True, 179: True, 185: pos_neg_weight(p_weight=s(0.1,0), n_weight=s(0.9,0)), 188: True, 194: pos_neg_weight(p_weight=s(0.18,0), n_weight=s(0.82,0)), 197: True, 203: pos_neg_weight(p_weight=s(0.08,0), n_weight=s(0.92,0)), 206: True, 212: pos_neg_weight(p_weight=s(0.56,0), n_weight=s(0.44,0)), 213: True, 216: pos_neg_weight(p_weight=s(0.7,0), n_weight=s(0.3,0)), 217: True, 220: pos_neg_weight(p_weight=s(0.48,0), n_weight=s(0.52,0)), 221: True, 224: pos_neg_weight(p_weight=s(0.58,0), n_weight=s(0.42,0)), 225: True, 228: True, 252: pos_neg_weight(p_weight=s(0.24,0), n_weight=s(0.76,0)), 255: pos_neg_weight(p_weight=s(0.36,0), n_weight=s(0.64,0)), 258: pos_neg_weight(p_weight=s(0.21,0), n_weight=s(0.79,0)), 261: pos_neg_weight(p_weight=s(0.36,0), n_weight=s(0.64,0)), 262: pos_neg_weight(p_weight=s(t,0), n_weight=s(t,0)), 265: pos_neg_weight(p_weight=s(0.42,0), n_weight=s(0.58,0)), 268: True, 350: pos_neg_weight(p_weight=s(1.0,-38), n_weight=s(1.0,11)), 422: pos_neg_weight(p_weight=s(1.0,18), n_weight=s(1.0,7)), 474: pos_neg_weight(p_weight=s(1.0,2), n_weight=s(1.0,20)), 540: pos_neg_weight(p_weight=s(1.0,33), n_weight=s(1.0,-48)), 588: pos_neg_weight(p_weight=s(1.0,-3), n_weight=s(1.0,-27)), 0: pos_neg_weight(p_weight=s(1.0,0), n_weight=s(1.0,0))}
decision_weights: [-1, 0, 0, 0, 0]
key_to_decision_index: {3: 1, 75: 2, 152: 3, 262: 4}

Gradients: {3: -0.15040698369600491, 75: -0.08597721671999992, 152: -0.000523708416000801, 262: 0.1658330396640011}
Updated to decisions: [-1, -0.15040698369600491, -0.08597721671999992, -0.000523708416000801, 0.1658330396640011]
Decisions: {dec_0: 0.4624689804563068, dec_1: 0.4785189266776132, dec_2: 0.4998690728989923, dec_3: 0.5413635099006627}
After epoch 1, expected utility: -36.61471132777641 and learning_rate 1.1

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 1.3081840225513912, 0.7083353796506305, 0.004227617795990924, -1.2069899291492687]
Decisions: {dec_0: 0.787209118479142, dec_1: 0.6700332352842705, dec_2: 0.5010569028748513, dec_3: 0.23023408159021866}
Worse eu -37.123213639405094, decreasing learning rate to 0.8800000000000001

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 1.016465821301912, 0.5494728603765046, 0.003277352553592579, -0.9324253353866148]
Decisions: {dec_0: 0.7342836128576551, dec_1: 0.6340132819436834, dec_2: 0.5008193374050203, dec_3: 0.28243292569554107}
Worse eu -37.031977566825525, decreasing learning rate to 0.7040000000000002

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 0.7830912603023288, 0.4223828449572037, 0.0025171403596739033, -0.7127736603764917]
Decisions: {dec_0: 0.686345968587507, dec_1: 0.6040533028984589, dec_2: 0.5006292847576563, dec_3: 0.3289862525628641}
Worse eu -36.95175100609558, decreasing learning rate to 0.5632000000000001

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 0.5963916115026621, 0.320710832621763, 0.0019089706045389626, -0.5370523203683931]
Decisions: {dec_0: 0.6448303305803454, dec_1: 0.5794974777309607, dec_2: 0.5004772425062054, dec_3: 0.36887355370352476}
Worse eu -36.88438691088972, decreasing learning rate to 0.4505600000000001

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 0.4470318924629286, 0.2393732227534104, 0.0014224348004310099, -0.3964752483619143]
Decisions: {dec_0: 0.6099333084882925, dec_1: 0.5595591840915166, dec_2: 0.5003556086401485, dec_3: 0.40215949314942273}
Worse eu -36.82939440041714, decreasing learning rate to 0.3604480000000001

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 0.32754411723114196, 0.17430313485872834, 0.0010332061571446476, -0.2840135907567312]
Decisions: {dec_0: 0.5811617030256317, dec_1: 0.5434657927656837, dec_2: 0.5002583015163078, dec_3: 0.4294700667181583}
Worse eu -36.785224635363534, decreasing learning rate to 0.28835840000000007

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 0.23195389704571256, 0.12224706454298268, 0.0007218232425155579, -0.19404426467258473]
Decisions: {dec_0: 0.5577298712502564, dec_1: 0.5305237624645233, dec_2: 0.5001804558027937, dec_3: 0.45164057917654465}
Worse eu -36.75005465172557, decreasing learning rate to 0.23068672000000007

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 0.15548172089736906, 0.08060220829038617, 0.00047271691081228625, -0.12206880380526758]
Decisions: {dec_0: 0.5387923127509433, dec_1: 0.5201396497876398, dec_2: 0.5001181792255024, dec_3: 0.4695206368758304}
Worse eu -36.72216558591866, decreasing learning rate to 0.18454937600000007

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 0.0943039799786943, 0.04728632328830895, 0.0002734318454496688, -0.06448843511141389]
Decisions: {dec_0: 0.5235585382694607, dec_1: 0.5118193785635162, dec_2: 0.5000683579609365, dec_3: 0.48388347622891364}
Worse eu -36.70008216915275, decreasing learning rate to 0.14763950080000007

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 0.045361787243754476, 0.0206336152866472, 0.00011400379315957491, -0.018424140156330898]
Decisions: {dec_0: 0.5113385026156804, dec_1: 0.5051582208152695, dec_2: 0.500028500948259, dec_3: 0.4953940952493041}
Worse eu -36.682595559916656, decreasing learning rate to 0.11811160064000006

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, 0.006208033055802614, -0.0006885511146822176, -1.3538648672500268e-05, 0.0184272958077355]
Decisions: {dec_0: 0.5015520032794788, dec_1: 0.49982786222813036, dec_2: 0.4999966153378319, dec_3: 0.5046066935965905}
Worse eu -36.66873837893932, decreasing learning rate to 0.09448928051200006

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.02511497029455889, -0.017746284235745757, -0.00011557260213816033, 0.04790844457898859]
Decisions: {dec_0: 0.49372158743808997, dec_1: 0.4955635453717305, dec_2: 0.49997110684949764, dec_3: 0.5119748208292727}
Worse eu -36.657745448406104, decreasing learning rate to 0.07559142440960005

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.050173372974848085, -0.03139247073259658, -0.00019719976491068845, 0.0714933635959911]
Decisions: {dec_0: 0.4874592874442835, dec_1: 0.4921525267716464, dec_2: 0.4999507000589321, dec_3: 0.5178657317860629}
Worse eu -36.64901458028135, decreasing learning rate to 0.06047313952768005

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.07022009511907944, -0.042309419930077245, -0.0002625014951287109, 0.09036129880959308]
Decisions: {dec_0: 0.48245218611477053, dec_1: 0.48942422260056395, dec_2: 0.4999343746265947, dec_3: 0.5225749661000529}
Worse eu -36.64207252851216, decreasing learning rate to 0.048378511622144044

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.08625747283446453, -0.05104297928806178, -0.0003147428793031289, 0.10545564698047469]
Decisions: {dec_0: 0.478448992390877, dec_1: 0.4872420250115485, dec_2: 0.49992131428082387, dec_3: 0.5263395063645369}
Worse eu -36.63654718221358, decreasing learning rate to 0.03870280929771524

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.0990873750067726, -0.0580298267744494, -0.00035653598664266335, 0.11753112551717995]
Decisions: {dec_0: 0.4752484045005859, dec_1: 0.4854966130435633, dec_2: 0.4999108660042835, dec_3: 0.5293490046217616}
Worse eu -36.632145515540806, decreasing learning rate to 0.03096224743817219

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.10935129674461906, -0.06361930476355951, -0.00038997047251429083, 0.1271915083465442]
Decisions: {dec_0: 0.47268938475091316, dec_1: 0.48410053609270015, dec_2: 0.49990250738310693, dec_3: 0.5317550783342804}
Worse eu -36.628636344382286, decreasing learning rate to 0.024769797950537756

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.11756243413489623, -0.06809088715484758, -0.00041671806121159287, 0.13491981461003555]
Decisions: {dec_0: 0.47064319519909575, dec_1: 0.48298385213156997, dec_2: 0.4998958204862048, dec_3: 0.5336788800909498}
Worse eu -36.625836917865925, decreasing learning rate to 0.019815838360430205

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.12413134404711797, -0.07166815306787805, -0.00043811613216943447, 0.14110245962082868]
Decisions: {dec_0: 0.46900695037284085, dec_1: 0.48209062677242526, dec_2: 0.49989047096870964, dec_3: 0.5352172033567657}
Worse eu -36.62360250323927, decreasing learning rate to 0.015852670688344166

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.12938647197689535, -0.07452996579830243, -0.00045523458893570776, 0.14604857562946316]
Decisions: {dec_0: 0.4676984324369196, dec_1: 0.48137612861181395, dec_2: 0.4998861913547315, dec_3: 0.5364473811409644}
Worse eu -36.62181828490841, decreasing learning rate to 0.012682136550675334

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.13359057432071728, -0.07681941598264191, -0.0004689293543487264, 0.15000546843637075]
Decisions: {dec_0: 0.46665193702912006, dec_1: 0.48080458477766586, dec_2: 0.49988276766356105, dec_3: 0.5374312047913211}
Worse eu -36.62039304721228, decreasing learning rate to 0.010145709240540268

Gradients: {3: 1.3259918238612691, 75: 0.7221023603369368, 152: 0.004319387465447022, 262: -1.248020880739336}
Updated to decisions: [-1, -0.1369538561957748, -0.07865097613011351, -0.00047988516667914135, 0.1531709826818968]
Decisions: {dec_0: 0.4658149515079882, dec_1: 0.48034738580652264, dec_2: 0.4998800287106326, dec_3: 0.5382180542761604}
Worse eu -36.61925423305436, decreasing learning rate to 0.008116567392432215
Final decisions: {dec_0: 0, dec_1: 0, dec_2: 0, dec_3: 1}
Final expected utility: -36.03621160959998
-------------------------------


Gradients: {3: -4.676851937487522, 75: 12.753348698175293, 152: -1.1094771335545026, 262: 1.1145363082209165}
Updated to decisions: [-1, -3.5786365826624387, 100, -0.980515401983082, 1.0268833145599274]
Decisions: {dec_0: 0.027155713131676498, dec_1: 1.0, dec_2: 0.2727895286111582, dec_3: 0.7363112153501461}
After epoch 1, expected utility: -36.6947883397746 and learning_rate 1.1

Gradients: {3: 33.75848788888392, 75: 0.0, 152: 12.126118151853875, 262: -4.555360279471714}
Updated to decisions: [-1, 100, 100, 100, -3.9840129928589585]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.01827077052341596}
Worse eu -37.45119233696599, decreasing learning rate to 0.8800000000000001

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, -2.907617511976762]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.05177828434390747}
Worse eu -37.41690599444649, decreasing learning rate to 0.7040000000000002

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, -2.1207173466694242]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.10709945189068044}
Worse eu -37.36029897462259, decreasing learning rate to 0.5632000000000001

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, -1.4911972144235541]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.1837421000834147}
Worse eu -37.281874890352604, decreasing learning rate to 0.4505600000000001

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, -0.9875811086268578]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.2713901186557911}
Worse eu -37.192189633427056, decreasing learning rate to 0.3604480000000001

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, -0.5846882239895008]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.3578545483326406}
Worse eu -37.103715476032555, decreasing learning rate to 0.28835840000000007

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, -0.26237391627961526]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.43478023679624517}
Worse eu -37.02500177267217, decreasing learning rate to 0.23068672000000007

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, -0.004522470111706811]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.49886938439908785}
Worse eu -36.95942297508471, decreasing learning rate to 0.18454937600000007

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.20175868682262]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.5502692631873538}
Worse eu -36.90682838812025, decreasing learning rate to 0.14763950080000007

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.3667836123700813]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.5906815577650923}
Worse eu -36.8654767742311, decreasing learning rate to 0.11811160064000006

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.49880355280805044]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.6221781205019375}
Worse eu -36.833248124144816, decreasing learning rate to 0.09448928051200006

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.6044195051584258]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.6466667672491061}
Worse eu -36.80819027787457, decreasing learning rate to 0.07559142440960005

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.688912267038726]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.665724911471919}
Worse eu -36.78868915749572, decreasing learning rate to 0.06047313952768005

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.7565064765429663]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.6805947719566343}
Worse eu -36.773473670828245, decreasing learning rate to 0.048378511622144044

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.8105818441463584]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.6922334779014531}
Worse eu -36.76156444173277, decreasing learning rate to 0.03870280929771524

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.8538421382290722]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.701372497047999}
Worse eu -36.75221300066708, decreasing learning rate to 0.03096224743817219

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.8884503734952431]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.708570280568344}
Worse eu -36.74484791615255, decreasing learning rate to 0.024769797950537756

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.9161369617081799]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.714254331585167}
Worse eu -36.739031748438485, decreasing learning rate to 0.019815838360430205

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.9382862322785294]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.7187533543754401}
Worse eu -36.734428153041456, decreasing learning rate to 0.015852670688344166

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.956005648734809]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.7223213571383974}
Worse eu -36.73077721774686, decreasing learning rate to 0.012682136550675334

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.9701811818998326]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.7251556097126218}
Worse eu -36.727877087493496, decreasing learning rate to 0.010145709240540268

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -4.471023666518964}
Updated to decisions: [-1, 100, 100, 100, 0.9815216084318515]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.7274100323567071}
Worse eu -36.72557026439186, decreasing learning rate to 0.008116567392432215
Final decisions: {dec_0: 1, dec_1: 1, dec_2: 1, dec_3: 1}
Final expected utility: -36.446644377856
-------------------------------


Gradients: {3: -4.4820002966110755, 75: -2.571862601155125, 152: -4.156730719895026, 262: 3.9257440596969744}
Updated to decisions: [-1, -3.1019104972368488, -2.237356467367284, -3.4443403257490526, 3.5851149176512767]
Decisions: {dec_0: 0.04302851755649286, dec_1: 0.09644566381777231, dec_2: 0.030938091914448036, dec_3: 0.9730149100812108}
After epoch 1, expected utility: -36.10302247959144 and learning_rate 1.1

Gradients: {3: 31.561666642394098, 75: 26.233258116611346, 152: 32.8212514335195, 262: -0.9216159461980175}
Updated to decisions: [-1, 100, 100, 100, 2.5713373768334575]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9289939655080725}
Worse eu -36.519300834332704, decreasing learning rate to 0.8800000000000001

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 2.766987435278474]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9408655973321789}
Worse eu -36.5071532653675, decreasing learning rate to 0.7040000000000002

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 2.9306129317530347]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9493391617233552}
Worse eu -36.49848274649125, decreasing learning rate to 0.5632000000000001

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.061513328932683]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9552769952504363}
Worse eu -36.49240689749739, decreasing learning rate to 0.4505600000000001

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.166233646676402]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9595436288407325}
Worse eu -36.48804109281651, decreasing learning rate to 0.3604480000000001

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.2500099008713765]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9626734684281016}
Worse eu -36.48483850510144, decreasing learning rate to 0.28835840000000007

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.317030904227357]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9650084719560451}
Worse eu -36.482449228141896, decreasing learning rate to 0.23068672000000007

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.3706477069121408]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9667745028105729}
Worse eu -36.480642148717784, decreasing learning rate to 0.18454937600000007

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.413541149059968]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9681250599085727}
Worse eu -36.47926020007479, decreasing learning rate to 0.14763950080000007

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.4478559027782296]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9691671347121251}
Worse eu -36.478193903905016, decreasing learning rate to 0.11811160064000006

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.475307705752839]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9699769738041251}
Worse eu -36.47736524139539, decreasing learning rate to 0.09448928051200006

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.4972691481325264]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9706099682999244}
Worse eu -36.476717533952446, decreasing learning rate to 0.07559142440960005

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.5148383020362766]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9711070279287861}
Worse eu -36.47620892096555, decreasing learning rate to 0.06047313952768005

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.5288936251592764]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9714987939969724}
Worse eu -36.47580804892015, decreasing learning rate to 0.048378511622144044

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.5401378836576765]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9718084898395646}
Worse eu -36.47549115469181, decreasing learning rate to 0.03870280929771524

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.5491332904563966]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9720538915744662}
Worse eu -36.4752400489851, decreasing learning rate to 0.03096224743817219

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.5563296158953728]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9722487179669431}
Worse eu -36.47504069416396, decreasing learning rate to 0.024769797950537756

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.5620866762465533]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9724036284734778}
Worse eu -36.47488218300987, decreasing learning rate to 0.019815838360430205

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.566692324527498]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9725269516430453}
Worse eu -36.47475599338998, decreasing learning rate to 0.015852670688344166

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.570376843152254]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9726252244357348}
Worse eu -36.474655436403005, decreasing learning rate to 0.012682136550675334

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.5733244580520584]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9727035966149431}
Worse eu -36.474575242587534, decreasing learning rate to 0.010145709240540268

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: -0.9296903208781845}
Updated to decisions: [-1, 100, 100, 100, 3.575682549971902]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 0.9727661373021776}
Worse eu -36.47451124824181, decreasing learning rate to 0.008116567392432215
Final decisions: {dec_0: 1, dec_1: 1, dec_2: 1, dec_3: 1}
Final expected utility: -36.446644377856
-------------------------------


Gradients: {3: 9.936856697322552, 75: -4.2621016459169585, 152: 11.147465232540263, 262: 9.24119536553444}
Updated to decisions: [-1, 100, -3.524315165929208, 100, 100]
Decisions: {dec_0: 1.0, dec_1: 0.028628252482602725, dec_2: 1.0, dec_3: 1.0}
After epoch 1, expected utility: -36.22904490287454 and learning_rate 1.1

Gradients: {3: 0.0, 75: 33.16480483467646, 152: 0.0, 262: 0.0}
Updated to decisions: [-1, 100, 100, 100, 100]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 1.0}
Worse eu -36.446644377856, decreasing learning rate to 0.8800000000000001

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: 0.0}
Updated to decisions: [-1, 100, 100, 100, 100]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 1.0}
Worse eu -36.446644377856, decreasing learning rate to 0.7040000000000002

Gradients: {3: 0.0, 75: 0.0, 152: 0.0, 262: 0.0}
Updated to decisions: [-1, 100, 100, 100, 100]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0, dec_3: 1.0}
Result converged.
Final decisions: {dec_0: 1, dec_1: 1, dec_2: 1, dec_3: 1}
Final expected utility: -36.446644377856
-------------------------------

