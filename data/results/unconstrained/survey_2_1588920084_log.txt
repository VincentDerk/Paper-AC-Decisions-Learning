Starting compilation
Compilation took 10.234737873077393 seconds.

Fixed weights: {1: pos_neg_weight(p_weight=s(0.09,0), n_weight=s(0.91,0)), 2: pos_neg_weight(p_weight=s(0.8,0), n_weight=s(0.2,0)), 3: pos_neg_weight(p_weight=s(0.25,0), n_weight=s(0.75,0)), 4: pos_neg_weight(p_weight=s(0.3,0), n_weight=s(0.7,0)), 5: pos_neg_weight(p_weight=s(t,0), n_weight=s(t,0)), 6: pos_neg_weight(p_weight=s(0.6,0), n_weight=s(0.4,0)), 7: True, 13: True, 21: pos_neg_weight(p_weight=s(0.4,0), n_weight=s(0.6,0)), 22: True, 28: True, 34: pos_neg_weight(p_weight=s(0.36,0), n_weight=s(0.64,0)), 37: pos_neg_weight(p_weight=s(0.28,0), n_weight=s(0.72,0)), 38: pos_neg_weight(p_weight=s(0.5,0), n_weight=s(0.5,0)), 39: True, 40: True, 48: True, 54: pos_neg_weight(p_weight=s(0.3,0), n_weight=s(0.7,0)), 57: pos_neg_weight(p_weight=s(0.12,0), n_weight=s(0.88,0)), 58: pos_neg_weight(p_weight=s(0.2,0), n_weight=s(0.8,0)), 59: True, 67: True, 73: pos_neg_weight(p_weight=s(0.1,0), n_weight=s(0.9,0)), 76: pos_neg_weight(p_weight=s(t,0), n_weight=s(t,0)), 77: pos_neg_weight(p_weight=s(0.28,0), n_weight=s(0.72,0)), 80: True, 88: pos_neg_weight(p_weight=s(0.75,0), n_weight=s(0.25,0)), 89: pos_neg_weight(p_weight=s(0.75,0), n_weight=s(0.25,0)), 90: True, 93: pos_neg_weight(p_weight=s(0.64,0), n_weight=s(0.36,0)), 94: True, 97: pos_neg_weight(p_weight=s(0.72,0), n_weight=s(0.28,0)), 98: True, 101: pos_neg_weight(p_weight=s(0.7,0), n_weight=s(0.3,0)), 102: True, 105: pos_neg_weight(p_weight=s(0.88,0), n_weight=s(0.12,0)), 106: True, 109: pos_neg_weight(p_weight=s(0.9,0), n_weight=s(0.1,0)), 110: True, 113: pos_neg_weight(p_weight=s(t,0), n_weight=s(t,0)), 114: pos_neg_weight(p_weight=s(0.64,0), n_weight=s(0.36,0)), 117: True, 125: True, 131: pos_neg_weight(p_weight=s(0.08,0), n_weight=s(0.92,0)), 134: pos_neg_weight(p_weight=s(0.04,0), n_weight=s(0.96,0)), 137: True, 143: True, 151: pos_neg_weight(p_weight=s(0.96,0), n_weight=s(0.04,0)), 152: True, 155: pos_neg_weight(p_weight=s(0.92,0), n_weight=s(0.08,0)), 156: True, 159: True, 165: pos_neg_weight(p_weight=s(0.25,0), n_weight=s(0.75,0)), 166: True, 169: pos_neg_weight(p_weight=s(0.2,0), n_weight=s(0.8,0)), 170: True, 173: True, 179: True, 185: pos_neg_weight(p_weight=s(0.1,0), n_weight=s(0.9,0)), 188: True, 194: pos_neg_weight(p_weight=s(0.18,0), n_weight=s(0.82,0)), 197: True, 203: pos_neg_weight(p_weight=s(0.08,0), n_weight=s(0.92,0)), 206: True, 212: pos_neg_weight(p_weight=s(0.24,0), n_weight=s(0.76,0)), 213: True, 216: pos_neg_weight(p_weight=s(0.36,0), n_weight=s(0.64,0)), 217: True, 220: pos_neg_weight(p_weight=s(0.42,0), n_weight=s(0.58,0)), 221: True, 224: pos_neg_weight(p_weight=s(0.21,0), n_weight=s(0.79,0)), 225: True, 228: True, 234: pos_neg_weight(p_weight=s(0.48,0), n_weight=s(0.52,0)), 237: pos_neg_weight(p_weight=s(0.58,0), n_weight=s(0.42,0)), 240: pos_neg_weight(p_weight=s(0.56,0), n_weight=s(0.44,0)), 243: pos_neg_weight(p_weight=s(0.7,0), n_weight=s(0.3,0)), 246: True, 372: pos_neg_weight(p_weight=s(1.0,-23), n_weight=s(1.0,-34)), 434: pos_neg_weight(p_weight=s(1.0,20), n_weight=s(1.0,-43)), 470: pos_neg_weight(p_weight=s(1.0,-11), n_weight=s(1.0,42)), 524: pos_neg_weight(p_weight=s(1.0,-33), n_weight=s(1.0,-24)), 606: pos_neg_weight(p_weight=s(1.0,28), n_weight=s(1.0,15)), 0: pos_neg_weight(p_weight=s(1.0,0), n_weight=s(1.0,0))}
decision_weights: [-1, 0, 0, 0]
key_to_decision_index: {5: 1, 76: 2, 113: 3}

Gradients: {5: -0.1532606839200028, 76: -0.13211962679999978, 113: -0.10715516927999857}
Updated to decisions: [-1, -0.1532606839200028, -0.13211962679999978, -0.10715516927999857]
Decisions: {dec_0: 0.46175965151015025, dec_1: 0.47323681120542543, dec_2: 0.4670180559717216}
After epoch 1, expected utility: -41.86896851084675 and learning_rate 1.1

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 1.5614899722572704, 1.3295803008770979, 1.0705754621155954]
Decisions: {dec_0: 0.826567050347232, dec_1: 0.744706337404834, dec_2: 0.7907712031567791}
Worse eu -42.3738853331584, decreasing learning rate to 0.8800000000000001

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 1.2185398410218158, 1.0372403153416785, 0.8350293358364768]
Decisions: {dec_0: 0.7718064864948413, dec_1: 0.6974173050679219, dec_2: 0.7383171721880918}
Worse eu -42.29408844443273, decreasing learning rate to 0.7040000000000002

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 0.9441797360334523, 0.8033683269133429, 0.6465924348131817]
Decisions: {dec_0: 0.7199431709183185, dec_1: 0.6562421653326396, dec_2: 0.6906945374733471}
Worse eu -42.22096544190093, decreasing learning rate to 0.5632000000000001

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 0.7246916520427613, 0.6162707361706744, 0.4958429139945457]
Decisions: {dec_0: 0.6736393129744414, dec_1: 0.6214819043836842, dec_2: 0.6493699113113961}
Worse eu -42.15695219722941, decreasing learning rate to 0.4505600000000001

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 0.5491011848502084, 0.4665926635765396, 0.37524329733963685]
Decisions: {dec_0: 0.6339270338959514, dec_1: 0.592725333746224, dec_2: 0.6145769691474805}
Worse eu -42.10265773576881, decreasing learning rate to 0.3604480000000001

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 0.4086288110961662, 0.3468502055012317, 0.27876360401570976]
Decisions: {dec_0: 0.6007590479437854, dec_1: 0.5692430789636932, dec_2: 0.5858535541411671}
Worse eu -42.05757373500032, decreasing learning rate to 0.28835840000000007

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 0.2962509120929324, 0.2510562390409854, 0.20157984935656809]
Decisions: {dec_0: 0.5735257663280073, dec_1: 0.5502250053451455, dec_2: 0.5624364602167607}
Worse eu -42.02065554312169, decreasing learning rate to 0.23068672000000007

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 0.20634859289034535, 0.17442106587278838, 0.13983284562925477]
Decisions: {dec_0: 0.5514048770018415, dec_1: 0.5349013604197947, dec_2: 0.543495052565047}
Worse eu -41.99069427813179, decreasing learning rate to 0.18454937600000007

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 0.13442673752827577, 0.11311292733823075, 0.09043524264740413]
Decisions: {dec_0: 0.53355616806625, dec_1: 0.5225934143447709, dec_2: 0.5282481197935894}
Worse eu -41.9665171515289, decreasing learning rate to 0.14763950080000007

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 0.07688925323862009, 0.06406641651058467, 0.05091716026192358]
Decisions: {dec_0: 0.5192128487804387, dec_1: 0.5127265406605505, dec_2: 0.5160111280216952}
Worse eu -41.9470770421669, decreasing learning rate to 0.11811160064000006

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, 0.03085926580689552, 0.024829207848467788, 0.01930269435353918]
Decisions: {dec_0: 0.5077142042787186, dec_1: 0.5048255237592115, dec_2: 0.506206983087036}
Worse eu -41.93148026673227, decreasing learning rate to 0.09448928051200006

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.005964724138484145, -0.006560559081225714, -0.005988878373168374]
Decisions: {dec_0: 0.49850882338645824, dec_1: 0.49850278488171446, dec_2: 0.49835986611243077}
Worse eu -41.918983761694804, decreasing learning rate to 0.07559142440960005

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.03542391609478787, -0.031672372624980516, -0.02622213655453441]
Decisions: {dec_0: 0.49114494694004235, dec_1: 0.49344484146788925, dec_2: 0.492082568689824}
Worse eu -41.90897926009211, decreasing learning rate to 0.06047313952768005

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.05899126965983084, -0.05176182345998437, -0.042408743099627236]
Decisions: {dec_0: 0.48525645792729527, dec_1: 0.4893994029432733, dec_2: 0.4870624326266795}
Worse eu -41.900973518391375, decreasing learning rate to 0.048378511622144044

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.07784515251186523, -0.06783338412798744, -0.0553580283357015]
Decisions: {dec_0: 0.48054853365626204, dec_1: 0.4861640261104824, dec_2: 0.48304815360986203}
Worse eu -41.894568853892096, decreasing learning rate to 0.03870280929771524

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.09292825879349273, -0.0806906326623899, -0.0657174565245609]
Decisions: {dec_0: 0.4767846395633426, dec_1: 0.48357654622268975, dec_2: 0.47983828002408807}
Worse eu -41.88944574247531, decreasing learning rate to 0.03096224743817219

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.10499474381879476, -0.09097643148991189, -0.07400499907564845]
Decisions: {dec_0: 0.47377540105822064, dec_1: 0.4815071894868731, dec_2: 0.4772715663553596}
Worse eu -41.885347991213635, decreasing learning rate to 0.024769797950537756

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.11464793183903635, -0.09920507055192945, -0.08063503311651846]
Decisions: {dec_0: 0.47136937060878015, dec_1: 0.4798521573251737, dec_2: 0.4752190528050096}
Worse eu -41.882070436990276, decreasing learning rate to 0.019815838360430205

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.12237048225522965, -0.10578798180154352, -0.08593906034921449]
Decisions: {dec_0: 0.46944549821154613, dec_1: 0.4785284481713699, dec_2: 0.47357764122000445}
Worse eu -41.8794488968931, decreasing learning rate to 0.015852670688344166

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.12854852258818428, -0.11105431080123476, -0.0901822821353713]
Decisions: {dec_0: 0.46790705110951397, dec_1: 0.4774696970167744, dec_2: 0.4722649213078876}
Worse eu -41.87735203263732, decreasing learning rate to 0.012682136550675334

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.13349095485454798, -0.11526737400098777, -0.09357685956429676]
Decisions: {dec_0: 0.46667673119186975, dec_1: 0.4766228413778955, dec_2: 0.4712150205753839}
Worse eu -41.87567480003799, decreasing learning rate to 0.010145709240540268

Gradients: {5: 1.5588642328884301, 76: 1.3288181160700887, 113: 1.0706642103596309}
Updated to decisions: [-1, -0.13744490066763895, -0.11863782456079017, -0.09629252150743711]
Decisions: {dec_0: 0.46569276628670775, dec_1: 0.4759454533983133, dec_2: 0.47037528287155583}
Worse eu -41.87433319156933, decreasing learning rate to 0.008116567392432215
Final decisions: {dec_0: 0, dec_1: 0, dec_2: 0}
Final expected utility: -41.13048934400001
-------------------------------


Gradients: {5: 20.493074197166642, 76: 2.3166098024861306, 113: -3.338932795275289}
Updated to decisions: [-1, 100, 2.100656386603199, -2.944470799232291]
Decisions: {dec_0: 1.0, dec_1: 0.04999848856851447, dec_2: 0.8909669597390876}
Worse eu -42.123813226689464, decreasing learning rate to 0.8

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, 1.7142349083139155, -2.3435071037983137]
Decisions: {dec_0: 1.0, dec_1: 0.0875832480026638, dec_2: 0.8473847648507177}
Worse eu -42.12833359642872, decreasing learning rate to 0.6400000000000001

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, 1.3281972434745464, -1.795913283830052]
Decisions: {dec_0: 1.0, dec_1: 0.1423492666649429, dec_2: 0.7905422813696983}
Worse eu -42.13746604576328, decreasing learning rate to 0.5120000000000001

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, 1.0193671116030507, -1.357838227855442]
Decisions: {dec_0: 1.0, dec_1: 0.20459187154281325, dec_2: 0.7348493021473773}
Worse eu -42.1512494393434, decreasing learning rate to 0.40960000000000013

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, 0.7723030061058545, -1.007378183075754]
Decisions: {dec_0: 1.0, dec_1: 0.2674932579193803, dec_2: 0.6840188695155408}
Worse eu -42.16726183656657, decreasing learning rate to 0.32768000000000014

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, 0.5746517217080973, -0.7270101472520036]
Decisions: {dec_0: 1.0, dec_1: 0.325851172619954, dec_2: 0.639835841329646}
Worse eu -42.18325464878292, decreasing learning rate to 0.2621440000000001

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, 0.4165306941898915, -0.5027157185930033]
Decisions: {dec_0: 1.0, dec_1: 0.376902677413258, dec_2: 0.602652778136417}
Worse eu -42.19780615480025, decreasing learning rate to 0.2097152000000001

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, 0.29003387217532695, -0.32328017566580314]
Decisions: {dec_0: 1.0, dec_1: 0.4198765525706204, dec_2: 0.5720044253806317}
Worse eu -42.210304142409754, decreasing learning rate to 0.1677721600000001

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, 0.18883641456367528, -0.1797317413240429]
Decisions: {dec_0: 1.0, dec_1: 0.45518763279209895, dec_2: 0.5470693155539791}
Worse eu -42.22066842905528, decreasing learning rate to 0.13421772800000006

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, 0.1078784484743539, -0.06489299385063474]
Decisions: {dec_0: 1.0, dec_1: 0.48378244228526884, dec_2: 0.5269434870332835}
Worse eu -42.22908682588161, decreasing learning rate to 0.10737418240000006

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, 0.04311207560289687, 0.026978004128091815]
Decisions: {dec_0: 1.0, dec_1: 0.5067440920006634, dec_2: 0.5107763498295885}
Worse eu -42.23584447897722, decreasing learning rate to 0.08589934592000005

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, -0.008701022694268812, 0.10047480251107305]
Decisions: {dec_0: 1.0, dec_1: 0.5250975904425201, dec_2: 0.49782475804998}
Worse eu -42.24123485650867, decreasing learning rate to 0.06871947673600004

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, -0.05015150133200133, 0.15927224121745803]
Decisions: {dec_0: 1.0, dec_1: 0.5397340990802225, dec_2: 0.4874647519167521}
Worse eu -42.24552156642471, decreasing learning rate to 0.054975581388800036

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, -0.08331188424218736, 0.20631019218256602]
Decisions: {dec_0: 1.0, dec_1: 0.5513953782785347, dec_2: 0.47918406760369686}
Worse eu -42.24892673261594, decreasing learning rate to 0.043980465111040035

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, -0.10984019057033617, 0.24394055295465242]
Decisions: {dec_0: 1.0, dec_1: 0.5606845068939911, dec_2: 0.4725675275750406}
Worse eu -42.25163145141442, decreasing learning rate to 0.03518437208883203

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, -0.13106283563285523, 0.2740448415723215]
Decisions: {dec_0: 1.0, dec_1: 0.5680856369132464, dec_2: 0.4672811133213429}
Worse eu -42.253780834312444, decreasing learning rate to 0.028147497671065627

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, -0.14804095168287046, 0.2981282724664568]
Decisions: {dec_0: 1.0, dec_1: 0.57398489382906, dec_2: 0.4630572076802282}
Worse eu -42.255490142981444, decreasing learning rate to 0.022517998136852502

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, -0.1616234445228827, 0.31739501718176505]
Decisions: {dec_0: 1.0, dec_1: 0.5786892670207319, dec_2: 0.45968186700119934}
Worse eu -42.25685056758137, decreasing learning rate to 0.018014398509482003

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, -0.17248943879489242, 0.33280841295401165]
Decisions: {dec_0: 1.0, dec_1: 0.5824425496600458, dec_2: 0.4569842400337914}
Worse eu -42.25793416322434, decreasing learning rate to 0.014411518807585602

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, -0.18118223421250024, 0.3451391295718089]
Decisions: {dec_0: 1.0, dec_1: 0.5854383363183224, dec_2: 0.4548279458174706}
Worse eu -42.258797877473306, decreasing learning rate to 0.011529215046068483

Gradients: {5: 0.0, 76: 2.4127354052460586, 113: -3.4224613748016397}
Updated to decisions: [-1, 100, -0.1881364705465865, 0.35500370286604677]
Decisions: {dec_0: 1.0, dec_1: 0.5878304356347196, dec_2: 0.45310412541708306}
Worse eu -42.259486761230725, decreasing learning rate to 0.009223372036854787
Final decisions: {dec_0: 1, dec_1: 1, dec_2: 0}
Final expected utility: -42.31854825919998
-------------------------------


Gradients: {5: -1.102907796892449, 76: -2.5356452826366596, 113: -2.134692081642134}
Updated to decisions: [-1, -1.0069411735500098, -2.2676057970807033, -1.9158603576380995]
Decisions: {dec_0: 0.26757889453453937, dec_1: 0.12832390177735586, dec_2: 0.09384160626024833}
After epoch 1, expected utility: -41.40060176476101 and learning_rate 1.1

Gradients: {5: 13.913872912675727, 76: 30.382540976307496, 113: 26.754657736061855}
Updated to decisions: [-1, 100, 100, 100]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0}
Worse eu -42.700631264000016, decreasing learning rate to 0.8800000000000001

Gradients: {5: 0.0, 76: 0.0, 113: 0.0}
Updated to decisions: [-1, 100, 100, 100]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0}
Worse eu -42.700631264000016, decreasing learning rate to 0.7040000000000002

Gradients: {5: 0.0, 76: 0.0, 113: 0.0}
Updated to decisions: [-1, 100, 100, 100]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0}
Result converged.
Final decisions: {dec_0: 1, dec_1: 1, dec_2: 1}
Final expected utility: -42.700631264000016
-------------------------------


Gradients: {5: -4.501595349835536, 76: 10.313070490427524, 113: -4.575998761519888}
Updated to decisions: [-1, -3.888145339229083, 100, -3.9316896987625176]
Decisions: {dec_0: 0.020072156395327546, dec_1: 0.019233333241545317, dec_2: 1.0}
After epoch 1, expected utility: -41.817783211335055 and learning_rate 1.1

Gradients: {5: 39.320364177565246, 76: 0.0, 113: 39.42476029726673}
Updated to decisions: [-1, 100, 100, 100]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0}
Worse eu -42.700631264000016, decreasing learning rate to 0.8800000000000001

Gradients: {5: 0.0, 76: 0.0, 113: 0.0}
Updated to decisions: [-1, 100, 100, 100]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0}
Worse eu -42.700631264000016, decreasing learning rate to 0.7040000000000002

Gradients: {5: 0.0, 76: 0.0, 113: 0.0}
Updated to decisions: [-1, 100, 100, 100]
Decisions: {dec_0: 1.0, dec_1: 1.0, dec_2: 1.0}
Result converged.
Final decisions: {dec_0: 1, dec_1: 1, dec_2: 1}
Final expected utility: -42.700631264000016
-------------------------------

